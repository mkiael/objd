{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee5ef6e-4602-416c-bf6d-8fe51e09b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d81a4b-dcb3-4b1d-952b-994130d27f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import subprocess\n",
    "import tarfile\n",
    "import wget\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52c761-22bf-452c-a911-dd33d75d78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ROOT = pathlib.Path('tf')\n",
    "CUSTOM_MODEL_NAME = 'od_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + PRETRAINED_MODEL_NAME + '.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "PROTOC_VERSION = '3.19.1'\n",
    "TENSORFLOW_VERSION = '2.6.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5127b-b08b-49cc-865c-c45675902474",
   "metadata": {},
   "outputs": [],
   "source": [
    "APIMODEL_PATH = TF_ROOT / 'models'\n",
    "PROTOC_PATH = TF_ROOT / 'protoc'\n",
    "SCRIPTS_PATH = TF_ROOT / 'scripts'\n",
    "WORKSPACE_PATH = TF_ROOT / 'workspace'\n",
    "ANNOTATION_PATH = TF_ROOT / 'workspace' / 'annotations'\n",
    "IMAGE_PATH = TF_ROOT / 'workspace' / 'images'\n",
    "MODEL_PATH =  TF_ROOT / 'workspace' / 'models'\n",
    "PRETRAINED_MODEL_PATH = TF_ROOT / 'workspace' / 'pre-trained-models'\n",
    "CHECKPOINT_PATH = TF_ROOT / 'workspace' / 'models' / CUSTOM_MODEL_NAME\n",
    "OUTPUT_PATH = TF_ROOT / 'workspace' / 'models' / CUSTOM_MODEL_NAME / 'export'\n",
    "TFJS_PATH = TF_ROOT / 'workspace' / 'models'/ CUSTOM_MODEL_NAME / 'tfjsexport'\n",
    "TFLITE_PATH = TF_ROOT / 'workspace' / 'models' / CUSTOM_MODEL_NAME / 'tfliteexport'\n",
    "\n",
    "paths = {\n",
    "    APIMODEL_PATH,\n",
    "    PROTOC_PATH,\n",
    "    SCRIPTS_PATH,\n",
    "    WORKSPACE_PATH,\n",
    "    ANNOTATION_PATH,\n",
    "    IMAGE_PATH,\n",
    "    MODEL_PATH,\n",
    "    PRETRAINED_MODEL_PATH,\n",
    "    CHECKPOINT_PATH,\n",
    "    OUTPUT_PATH,\n",
    "    TFJS_PATH,\n",
    "    TFLITE_PATH\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2c014-477b-4be5-886c-2a74e7f1d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG = CHECKPOINT_PATH / 'pipeline.config'\n",
    "TF_RECORD_SCRIPT = SCRIPTS_PATH / TF_RECORD_SCRIPT_NAME\n",
    "LABELMAP = ANNOTATION_PATH / LABEL_MAP_NAME\n",
    "\n",
    "files = {\n",
    "    PIPELINE_CONFIG,\n",
    "    TF_RECORD_SCRIPT,\n",
    "    LABELMAP\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974b08a-d77a-444f-9f1f-453abb0d1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb6c1e-2999-4394-bd33-19d47f6666d2",
   "metadata": {},
   "source": [
    "### Clone Tensorflow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5762208-f618-4c66-ac82-e74068667982",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not APIMODEL_PATH.joinpath('research', 'object_detection').exists():\n",
    "    !git clone https://github.com/tensorflow/models {str(APIMODEL_PATH)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae9d2e-3137-447f-ae85-6f417c29a9a0",
   "metadata": {},
   "source": [
    "### Install Tensorflow and object detection library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bb921-afe0-42f2-b803-ea2f1c1092d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "protoc_zip = 'protoc-' + PROTOC_VERSION + '-win64.zip'\n",
    "wget.download('https://github.com/protocolbuffers/protobuf/releases/download/v' + PROTOC_VERSION + '/' + protoc_zip)\n",
    "\n",
    "with zipfile.ZipFile(protoc_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(str(PROTOC_PATH))\n",
    "\n",
    "os.remove(protoc_zip)\n",
    "os.environ['PATH'] += os.pathsep + str(PROTOC_PATH.joinpath('bin').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253fb2e-f768-494a-957d-4ebed902fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu=={TENSORFLOW_VERSION}\n",
    "subprocess.run(['protoc', 'object_detection/protos/*.proto', '--python_out=.'], cwd=str(TF_ROOT / 'models' / 'research'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686d17e-45e5-4dfe-91f2-652aadc77b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(TF_ROOT / 'models' / 'research' / 'object_detection' / 'packages' / 'tf2' / 'setup.py', TF_ROOT / 'models' / 'research' / 'setup.py')\n",
    "result = subprocess.run(['pip', 'install', '-e', '.'], cwd=str(TF_ROOT / 'models' / 'research'), capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733b0eaa-9ca6-4566-9d58-8946f309197a",
   "metadata": {},
   "source": [
    "### Verify installtion of object detection library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc70eb5-74e2-4f2b-82fb-f2d582c767c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = APIMODEL_PATH / 'research' / 'object_detection' / 'builders' / 'model_builder_tf2_test.py'\n",
    "!python {str(VERIFICATION_SCRIPT)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec801f75-6066-4bf0-abd9-db3e38c862e4",
   "metadata": {},
   "source": [
    "## Prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d286e-111a-46b5-aefc-b92eb2dfc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tar = PRETRAINED_MODEL_NAME + '.tar.gz'\n",
    "wget.download(PRETRAINED_MODEL_URL)\n",
    "\n",
    "with tarfile.open(model_tar, 'r:gz') as tar_ref:\n",
    "    tar_ref.extractall(path=PRETRAINED_MODEL_PATH)\n",
    "\n",
    "os.remove(model_tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f04b8c-7cc2-4295-992c-219df7a2452a",
   "metadata": {},
   "source": [
    "### Create label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6880297-09e2-4be2-bae5-c383e1fe3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'SmallYellowMachine', 'id':1}, {'name':'BigYellowMachine', 'id':2}]\n",
    "with LABELMAP.open('w') as lm_file:\n",
    "    for label in labels:\n",
    "        lm_file.write('item { \\n')\n",
    "        lm_file.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        lm_file.write('\\tid:{}\\n'.format(label['id']))\n",
    "        lm_file.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d18415-8cc0-4958-91a2-2d3ef579f21e",
   "metadata": {},
   "source": [
    "### Generate tf records from image annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7363282-f37e-4bf2-a6de-093d0c09f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0908d-04a8-4995-b368-5082477abe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "from collections import namedtuple\n",
    "from object_detection.utils import label_map_util\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231f028-0962-45d7-9c63-5efd99c10abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tfrecord(xml_dir, output_path):\n",
    "    # Convert annotation xml files to panda data frame\n",
    "    rows = []\n",
    "    for xml_file in xml_dir.glob('**/*.xml'):\n",
    "        root = et.parse(xml_file).getroot()\n",
    "        for annot in root.findall('object'):\n",
    "            filename = root.find('filename').text\n",
    "            \n",
    "            size = root.find('size')\n",
    "            width = int(size[0].text)\n",
    "            height = int(size[1].text)\n",
    "            \n",
    "            label_name = annot[0].text\n",
    "            bbox = annot[4]\n",
    "            bbox_ymin = int(bbox[0].text)\n",
    "            bbox_ymax = int(bbox[1].text)\n",
    "            bbox_xmin = int(bbox[2].text)\n",
    "            bbox_xmax = int(bbox[3].text)\n",
    "            \n",
    "            rows.append((filename,\n",
    "                         width,\n",
    "                         height,\n",
    "                         label_name,\n",
    "                         bbox_ymin,\n",
    "                         bbox_ymax,\n",
    "                         bbox_xmin,\n",
    "                         bbox_xmax))\n",
    "            \n",
    "    column_name = ['filename',\n",
    "                   'width',\n",
    "                   'height',\n",
    "                   'class',\n",
    "                   'xmin',\n",
    "                   'ymin',\n",
    "                   'xmax',\n",
    "                   'ymax']\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=column_name)\n",
    "    \n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby('filename')\n",
    "    grouped = [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "        \n",
    "    label_map = label_map_util.get_label_map_dict(label_map_util.load_labelmap(LABELMAP))\n",
    "    \n",
    "    with tf.io.TFRecordWriter(str(output_path)) as writer:\n",
    "        for group in grouped:\n",
    "            with tf.io.gfile.GFile(xml_dir.joinpath(group.filename), 'rb') as fid:\n",
    "                enc_jpg = fid.read()\n",
    "                \n",
    "            enc_jpg_io = io.BytesIO(enc_jpg)\n",
    "            img_width, img_height = Image.open(enc_jpg_io).size\n",
    "\n",
    "            filename = group.filename.encode('utf8')\n",
    "            img_format = b'jpg'\n",
    "            xmins = []\n",
    "            xmaxs = []\n",
    "            ymins = []\n",
    "            ymaxs = []\n",
    "            classes_text = []\n",
    "            classes = []\n",
    "\n",
    "            for index, row in group.object.iterrows():\n",
    "                xmins.append(row['xmin'] / img_width)\n",
    "                xmaxs.append(row['xmax'] / img_width)\n",
    "                ymins.append(row['ymin'] / img_height)\n",
    "                ymaxs.append(row['ymax'] / img_height)\n",
    "                classes_text.append(row['class'].encode('utf8'))\n",
    "                classes.append(label_map[row['class']])\n",
    "\n",
    "            tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/height': dataset_util.int64_feature(img_width),\n",
    "                'image/width': dataset_util.int64_feature(img_height),\n",
    "                'image/filename': dataset_util.bytes_feature(filename),\n",
    "                'image/source_id': dataset_util.bytes_feature(filename),\n",
    "                'image/encoded': dataset_util.bytes_feature(enc_jpg),\n",
    "                'image/format': dataset_util.bytes_feature(img_format),\n",
    "                'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "                'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "                'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "                'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "                'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "                'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "            }))\n",
    "            writer.write(tf_example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55cfaad-9b0e-46f4-9d4c-39bb3b3e02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tfrecord(IMAGE_PATH / 'train', ANNOTATION_PATH / 'train.record')\n",
    "gen_tfrecord(IMAGE_PATH / 'test', ANNOTATION_PATH / 'test.record')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25fb22b-c32a-4d92-add3-e4a0b70041ad",
   "metadata": {},
   "source": [
    "### Update pipeline config for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb6258-640a-45f7-9fd7-0fea73f836d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(PRETRAINED_MODEL_PATH / PRETRAINED_MODEL_NAME / 'pipeline.config', CHECKPOINT_PATH / 'pipeline.config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22e6b5-8a5f-45d1-9c03-6a53bfcefbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8b157-00e6-4c9c-a0e7-c075547a742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(PIPELINE_CONFIG, 'r') as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "    \n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 2\n",
    "pipeline_config.train_config.fine_tune_checkpoint = str(PRETRAINED_MODEL_PATH / PRETRAINED_MODEL_NAME / 'checkpoint' / 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= str(LABELMAP)\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [str(ANNOTATION_PATH / 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = str(LABELMAP)\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [str(ANNOTATION_PATH / 'test.record')]\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(PIPELINE_CONFIG, \"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc7256-0004-49a2-8e03-6dac83ab3096",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f4610-3535-465d-8a7d-883f39f4bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = APIMODEL_PATH / 'research' / 'object_detection' / 'model_main_tf2.py'\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, str(CHECKPOINT_PATH), str(PIPELINE_CONFIG))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7b905-c177-4f5a-8dd6-1f3f0da790f7",
   "metadata": {},
   "source": [
    "## Run detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74929c4-7675-4b05-8551-4a6e883b68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "from tensorflow.python.eager import def_function\n",
    "def_function.ALLOW_DYNAMIC_VARIABLE_CREATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b2675-b278-45f8-bb18-109c6f9bb05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(str(CHECKPOINT_PATH / 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476fbc2e-50c5-4cd9-81fe-b95f14c83fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6c13e-16d9-44c4-8a51-acf89188ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)\n",
    "\n",
    "image_np = np.array(Image.open(str(IMAGE_PATH / 'test' / 'sym17.jpg')))\n",
    "image = np.asarray(image_np)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "input_tensor = input_tensor[tf.newaxis,...]\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odenv",
   "language": "python",
   "name": "odenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
